# -*- coding: utf-8 -*-
"""pretrained_cifar100.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JjruwikliekqKdtt1q-ZaVuet5EciUgY
"""

import torch
import torch.nn as nn
import torch.utils.model_zoo as model_zoo
import torchvision

model_urls = {
    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
}
# Loading the data

def resnet18(pretrained=True):
    model = torchvision.models.resnet.ResNet(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2])
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls['resnet18'],model_dir='./'))
    return model

model = resnet18(pretrained=True)

# If you just need to fine-tune the last layer, comment out the code below.
# for param in model.parameters():
#     param.requires_grad = False
model.fc = nn.Linear(model.fc.in_features, 100)

import torch
import torch.utils.data
import torchvision
import torchvision.transforms as transforms
import time
import torch.nn as nn
import numpy as np
from torch import optim

# We provide the code for loading CIFAR100 data
num_epochs = 50
batch_size = 128
learning_rate = 0.001
# torch.manual_seed(0)
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    
])

transform_test = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])


train_dataset = torchvision.datasets.CIFAR100(root='~/scratch/', train=True, download=True, transform=transform_train)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)

test_dataset = torchvision.datasets.CIFAR100(root='~/scratch/', train=False, download=False, transform=transform_test)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

input_shape = np.array(train_dataset[0][0]).shape
input_dim = input_shape[1]*input_shape[2]*input_shape[0]


step = 0
start_time = time.time()
model = model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=1, verbose=True, min_lr=0.0001)

epoch_list,train_acc_list,test_acc_list = [],[],[]

for epoch in range(num_epochs):
  
  correct = 0
  total = 0
  total_loss = 0
  ## Train
  model.train()
  for images,labels in train_loader:
    images = images.to(device)
    labels = labels.to(device)
    #Forward Pass
    outputs = model(images)

    loss = criterion(outputs,labels)
    _,predicted = torch.max(outputs.data,1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
    #Backward and optimize
    optimizer.zero_grad()
    loss.backward()
    total_loss += loss.item()
    optimizer.step()
    step += 1
    train_accuracy = correct/total
    train_loss = total_loss/step

  ## Test
  model.eval()
  with torch.no_grad():
    correct = 0
    total = 0
    for images,labels in test_loader:
      images, labels = images.to(device), labels.to(device)
      outputs = model(images)
      _, predicted = torch.max(outputs.data,1)
      total += labels.size(0)
      correct += (predicted == labels).sum().item()
    test_accuracy = correct/total
    
    epoch_list.append(epoch)
    train_acc_list.append(train_accuracy)
    test_acc_list.append(test_accuracy)
    print('Epoch {}, Time {:.4f}, Loss: {:.4f}, Train Accuracy: {:.4f}, Test Accuracy: {:.4f}'.format(
        epoch,time.time()-start_time,train_loss,train_accuracy,test_accuracy))
  
  scheduler.step(test_accuracy)
  if test_accuracy > 0.7:
    break

import matplotlib.pyplot as plt
plt.plot(epoch_list,train_acc_list,label='train_accuracy')
plt.plot(epoch_list,test_acc_list,label='test_accuracy')
plt.title('Learning Curve for Pre-trained ResNet on CIFAR100')
plt.xlabel('num_epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()
